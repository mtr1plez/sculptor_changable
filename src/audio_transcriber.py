# -*- coding: utf-8 -*-
import whisper
import yaml
import json
import os
import torch

def load_config():
    with open("config.yaml", "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def transcribe_audio():
    cfg = load_config()
    
    input_audio = cfg['paths']['input_audio']
    cache_dir = cfg['paths']['cache_dir']
    output_file = os.path.join(cache_dir, "transcript.json")
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
    if os.path.exists(output_file):
        print(f"‚è© –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫—ç—à–µ: {output_file}")
        with open(output_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    print(f"üëÇ –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é: {input_audio}")
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (Whisper —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –Ω–∞ CPU, –∏ –Ω–∞ GPU)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º device –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞, –Ω–æ –¥–ª—è Whisper –ª—É—á—à–µ —è–≤–Ω–æ —É–∫–∞–∑–∞—Ç—å cuda –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ cpu
    device = cfg['models']['device']
    model_size = cfg['models']['whisper_size']
    
    print(f"   –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper ({model_size}) –Ω–∞ {device}...")
    model = whisper.load_model(model_size, device=device)
    
    # 3. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
    result = model.transcribe(input_audio, verbose=False)
    
    segments = []
    for seg in result["segments"]:
        segments.append({
            "start": seg["start"],
            "end": seg["end"],
            "text": seg["text"].strip()
        })
    
    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    os.makedirs(cache_dir, exist_ok=True)
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(segments, f, ensure_ascii=False, indent=2)
        
    print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_file}")
    return segments

if __name__ == "__main__":
    transcribe_audio()